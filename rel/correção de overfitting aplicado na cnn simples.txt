As principais medidas de correção de overfitting aplicadas neste treino são:

1. **Dropout:** Camadas `nn.Dropout(0.45)` são usadas após cada camada convolucional e após a primeira camada linear. O dropout desativa aleatoriamente uma fração dos neurônios durante o treino, ajudando a evitar que o modelo dependa demais de neurônios específicos.

2. **Data Augmentation:** No transform do dataset de treino (`train_transform`), são aplicadas transformações como `RandomCrop` (recorte aleatório com padding) e `RandomHorizontalFlip` (espelhamento horizontal aleatório). Isso aumenta a variedade dos dados de entrada, tornando o modelo mais robusto.
FOI PRECISO CONVERTER A IMAGEM PARA PIL.IMAGE PARA DAR COM O TORCHVIVIOSN

3. **Weight Decay:** O otimizador Adam é configurado com o parâmetro `weight_decay=7.5e-4`, que adiciona uma penalização L2 aos pesos do modelo, ajudando a evitar que eles cresçam demais e reduzindo o risco de overfitting.

Essas três estratégias são as principais técnicas de regularização presentes neste código para combater o overfitting.
